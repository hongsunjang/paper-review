# NASPipe

## Intro

> Casual dependnecy: two subnet shared layer has dependency
> BSP (bulk synchronchronous parallel): ?
이전 방법들은
1. Casual dependency를 고려하지 못함 Retarii같은 경우 BSP는 bulk 내에서의 casual dependencies를 보장하지 못함
2. Not efficiently manage extra large super net context
 subnet만 GPU 메모리에 올리기 위해선 
 prefetching subnet from CPU to GPU가 필요하지만 
  => subnet is generated by the exploration algorithm
  => 다음 subnet이 뭐가 될지 직전까지도 알 수 없다.
 게다가 DNN operator의 switching feature를 efficient하게 활용하는 이전 논문들이 있다(PipeSwitch, VPipe)

Retarii는 subnet task를 GPU에 할당했지만, subnet을 stage로 나누어 subset of layer를 GPU에 할당하는 것

NASPipe의 장점
1. efficiently Resolve casual dependencies and perform synchronization in training
 => Retiarii는 levearge global sync server

 2. subnet memory 덜 쓸 수 있다.

NASPipe의 insight
1. Larger search space -> fewer dependencies

2.  swap in the context of subnets to be executed 가 시간에 큰 차지를 하는 것을 발견 (VPIPE에서 제시한것 같다.)
=> DNN computation time is roughly deterministic

![comparison](images/comparison.png)


## Background

1. reproducibility for supernet => 재 구현 했을 때 동일성
- intra-subnet
쉽다! 왜냐하면 layer에서 하나의 candidate만 겹치므로

- inter subnet reproducibility
어렵다, 특히 병렬 처리 상황에서 더 어렵다.
왜냐하면 casual depedency 발생

reproducibility는연구적 측면에서 중요

2. how to parallel the task?

Retiarii와 NASPipe는  inter-subnet parlalle task 
을 지지한다 -> multiple subnet with one input batch

다른 방법인 intra-subnet parallel task는 -> micro batch를 쓰는 것이다

왜 inter-subnet parallel task가 더 좋을까?
-> intra subnet parallel은 large batch size 일때 GPU utilization이 효과적으로 쓰일 수 있다.

Retiarii와 다른점은 뭘까? ratiarii는 selected parallelism을 써서 subnet를 결정해서 한 GPU가 그 subnet train을 처리하게 만든다. 그와 달리 NASPipe는 pipeline parallelism을 사용하여 메모리도 아까고, scalablity가 좋다.



